{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support,f1_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(res_filename, labels = [0,1]):\n",
    "  res=pd.read_csv(res_filename)\n",
    "  res =res.rename(columns={\"annotation\":\"gold\"})\n",
    "  # res = res.sample(20)\n",
    "  if res_filename.split(\"/\")[2].split(\"_\")[0] == \"CN\" : \n",
    "      res[\"gold_formatted\"] = res[\"gold\"].map({\"yes\":1, \"no\":0})\n",
    "  elif res_filename.split(\"/\")[2].split(\"_\")[0].startswith(\"SX\"):\n",
    "     res[\"gold_formatted\"] = res[\"gold\"].map({\"Sexiste\":1, \"NonSexiste\":0, \"Sexiste-reportage\":0})\n",
    "\n",
    "  def format_answer(string: str):\n",
    "    if string.lower() in ['oui', 'yes']:return 1\n",
    "    elif string.lower() in [\"non\", \"no\"]:return 0\n",
    "    else: return np.nan\n",
    "      \n",
    "  res[\"pred_formatted\"] = res[\"pred\"].apply(format_answer)\n",
    "  res = res[res.pred_formatted.notna()]\n",
    "  # print(res)\n",
    "  conf_mtx = confusion_matrix(res[\"gold_formatted\"], res[\"pred_formatted\"], labels=labels) \n",
    "  acc = accuracy_score(res[\"gold_formatted\"], res[\"pred_formatted\"])\n",
    "  prec,rec,f1,_ = precision_recall_fscore_support(res[\"gold_formatted\"], res[\"pred_formatted\"],labels=labels, zero_division=np.nan)\n",
    "  macro = f1_score(res[\"gold_formatted\"], res[\"pred_formatted\"], average=\"macro\",labels=labels, zero_division=np.nan)\n",
    "  weight = f1_score(res[\"gold_formatted\"], res[\"pred_formatted\"], average=\"weighted\",labels=labels, zero_division=np.nan)\n",
    "\n",
    "  metrics = [acc, prec[1], rec[1], f1[1], macro, weight]\n",
    "  metrics = [round(metric,2) for metric in metrics]\n",
    "  # print(conf_mtx)\n",
    "  # print(metrics)\n",
    "  return res, conf_mtx, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = \"test_flabT5/flanT5_large\"\n",
    "directory = \"test_flabT5/flanT5_XL\"\n",
    "directory = \"llmjudge_experiment/test4\"\n",
    "\n",
    "filenames= os.listdir(directory)\n",
    "filenames = [filename for filename in filenames if filename.endswith(\"csv\")]\n",
    "conf_mtxs = []; metrics = []\n",
    "for filename in filenames :\n",
    "    # print(filename)\n",
    "    eval = evaluate(res_filename=os.path.join(directory,filename))\n",
    "    # print(filename); print(eval[1]); print(eval[2]); print() ## PRINT to PEEk\n",
    "    conf_mtxs.append(eval[1])\n",
    "    metrics.append(eval[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_map = {\"SX\":\"sexism full\", \"CN\":\"conan\", \"SXM\":\"sexism most\", \"SXL\":\"sexism least\"}\n",
    "current_time = datetime.now().strftime(\"%d%m\")\n",
    "filenames = sorted(filenames)\n",
    "with open (f\"{directory}/brief_{current_time}.txt\", \"w\") as file:\n",
    "    file.write(f\"Brief on... \\n- Pipeline name : {directory.split('/',1)[1]} \\n\")\n",
    "    file.write(\"------------------------------\\n\")\n",
    "    for filename,conf_mtx,metric in zip(filenames,conf_mtxs,metrics):\n",
    "        file.write(filename+\"\\n\")\n",
    "        # file.write(f\"Prompting type : {(filename.split('_',2)[-1]).split('.')[0]}\\n\")\n",
    "        file.write(f\"\"\"[tn, fp]    {conf_mtx[0]}\n",
    "[fn, tp]    {conf_mtx[1]}\n",
    "Acc     Prec    Rec     F1      F1m     F1w\n",
    "{'    '.join(map(str, metric))}\n",
    "\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".eunkyung_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
